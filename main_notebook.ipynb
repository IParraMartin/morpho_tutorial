{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install and load the libraries\n",
    "pip install spacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# set the text to analyze\n",
    "doc = nlp(\"Don Quixote and Sancho ran to the store taking the map.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try different attributes\n",
    "for token in doc:\n",
    "    print(token.text, \n",
    "          token.lemma_, \n",
    "          token.pos_, \n",
    "          token.tag_, \n",
    "          token.dep_, \n",
    "          token.morph\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Don Quixote\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sancho\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " ran to the store.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try named entity recognition\n",
    "spacy.displacy.render(doc, \n",
    "                      style='ent', \n",
    "                      jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.displacy.render(doc, \n",
    "                      style='dep', \n",
    "                      jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token_a in doc:\n",
    "    for token_b in doc:\n",
    "        print(f'Similarity between \"{token_a}\" and \"{token_b}\" is: {token_a.similarity(token_b)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ran', 'VERB', Tense=Past|VerbForm=Fin], ['taking', 'VERB', Aspect=Prog|Tense=Pres|VerbForm=Part]]\n"
     ]
    }
   ],
   "source": [
    "# get the verbs and their morph to analyze actions\n",
    "pos_tag = [[token.text, token.pos_, token.morph] for token in doc if token.pos_ != 'PUNCT' and token.pos_ == 'VERB']\n",
    "print(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to extract the similarities into a csv file\n",
    "def get_similarities(doc):\n",
    "    similarities = []\n",
    "    for token_a in doc:\n",
    "        for token_b in doc:\n",
    "            similarities.append([token_a, token_b, token_a.similarity(token_b)])\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inigoparra/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# create a csv file with the similarities\n",
    "import csv\n",
    "with open('don_quixote.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for i in get_similarities(doc):\n",
    "        writer.writerow(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
